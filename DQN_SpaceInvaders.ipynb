{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN-SpaceInvaders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemaZ/Deep-Reinforcement-Learning/blob/master/DQN_SpaceInvaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5QbuUFdbI7zg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.atarimania.com/roms/Roms.rar && unrar x Roms.rar && unzip Roms/ROMS.zip\n",
        "! pip3 install gym-retro\n",
        "! python3 -m retro.import ROMS/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-58hxRSyFe3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import retro                 # Retro Environment\n",
        "\n",
        "\n",
        "from skimage import transform # Help us to preprocess the frames\n",
        "from skimage.color import rgb2gray # Help us to gray our frames\n",
        "\n",
        "import matplotlib.pyplot as plt # Display graphs\n",
        "\n",
        "from collections import deque # Ordered collection with ends\n",
        "\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Apw4X9UgM44o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GameEnv:\n",
        "  \n",
        "  def __init__(self, game = 'SpaceInvaders-Atari2600'):\n",
        "    self.env = retro.make(game)\n",
        "    self.n_actions = self.env.action_space.n\n",
        "    self.frame_size = self.env.observation_space.shape\n",
        "    self.hot_enc_actions = np.array(np.identity(self.n_actions).tolist()) \n",
        "    self.stack_size = 4\n",
        "    self.stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(self.stack_size)], maxlen=self.stack_size)\n",
        "    self.hyperparameters = {\n",
        "                           'learning_rate' : 0.00025,\n",
        "                           'total_episodes' : 500,\n",
        "                           'max_steps' : 5000,\n",
        "                           'btach_size': 64,\n",
        "                           'explore_start' : 1,\n",
        "                           'explore_end' : 0.01,\n",
        "                           'decay_rate' : 0.00001,\n",
        "                           'gamma' : 0.9,\n",
        "                           'pretrain_length' : 64,\n",
        "                           'memory_size' : 1000000,\n",
        "                           'state_size' : [110, 84, 4]\n",
        "                           }\n",
        "    self.training = False\n",
        "    self.render = False\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  def _preprocess_frame(self,frame):\n",
        "    gray_frame = rgb2gray(frame)\n",
        "    cropped_frame = gray_frame[8:-12,4:-12]\n",
        "    \n",
        "    # Normalize Pixel Values\n",
        "    normalized_frame = cropped_frame/255.0\n",
        "    \n",
        "    # Resize\n",
        "    # Thanks to Miko≈Çaj Walkowiak\n",
        "    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n",
        "    \n",
        "    return preprocessed_frame # 110x84x1 frame\n",
        "  \n",
        "  def stack_frame(self, frame, new_epis = False):\n",
        "    \n",
        "    processed_frame = self._preprocess_frame(frame)\n",
        "    \n",
        "    if new_epis:\n",
        "      self.stacked_frames  =  deque([frame for _ in range(self.stack_size)], maxlen=self.stack_size)\n",
        "    else:\n",
        "      self.stacked_frames.append(frame)\n",
        "    \n",
        "    self.stacked_state = np.stack(self.stacked_frames, axis=2)\n",
        "      \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwXpTh-0yvBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeepQNN:\n",
        "  \n",
        "  def __init__(self, gamenv):\n",
        "    self.gamenv = gamenv\n",
        "    with tf.variable_scope('DQNN'):\n",
        "      self._inputs = tf.placeholder(tf.float32, [None, *self.gamenv.hyperparameters['state_size']], name='inputs')\n",
        "      self._actions = tf.placeholder(tf.float32, [None, self.gamenv.n_actions], name='actions')\n",
        "      self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
        "      \n",
        "      self.conv1 = tf.layers.conv2d(inputs = self._inputs, \n",
        "                                    filters = 32,\n",
        "                                    kernel_size = [8,8],\n",
        "                                    strides = [4,4],\n",
        "                                    padding = 'VALID',\n",
        "                                    kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                    name = 'Conv1')\n",
        "      self.actvf1 = tf.nn.elu(self.conv1, name='Elu1')\n",
        "      \n",
        "      self.conv2 = tf.layers.conv2d(inputs = self.conv1, \n",
        "                                    filters = 64,\n",
        "                                    kernel_size = [4,4],\n",
        "                                    strides = [2,2],\n",
        "                                    padding = 'VALID',\n",
        "                                    kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                    name = 'Conv2')\n",
        "      self.actvf2 = tf.nn.elu(self.conv2, name='Elu2')\n",
        "      \n",
        "      self.conv3 = tf.layers.conv2d(inputs = self.conv2, \n",
        "                                    filters = 64,\n",
        "                                    kernel_size = [3,3],\n",
        "                                    strides = [2,2],\n",
        "                                    padding = 'VALID',\n",
        "                                    kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                    name = 'Conv3')\n",
        "      self.actvf3 = tf.nn.elu(self.conv3, name='Elu3')\n",
        "      \n",
        "      self.flatten = tf.contrib.layers.flatten(self.actvf3)\n",
        "      self.fc = tf.layers.dense(inputs = self.flatten,\n",
        "                                units = 512,\n",
        "                                activation = tf.nn.elu,\n",
        "                                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "                                name=\"fc1\")\n",
        "            \n",
        "      self.output = tf.layers.dense(inputs = self.fc, \n",
        "                                   kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "                                   units = self.gamenv.n_actions, \n",
        "                                   activation=None)\n",
        "      self.Q = tf.reduce_sum(tf.multiply(self.output, self._actions))\n",
        "            \n",
        "            # The loss is the difference between our predicted Q_values and the Q_target\n",
        "            # Sum(Qtarget - Q)^2\n",
        "      self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
        "            \n",
        "      self.optimizer = tf.train.AdamOptimizer(self.gamenv.hyperparameters['learning_rate']).minimize(self.loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocsvpr9UylOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spaceinvaders = GameEnv()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aL3io1jWzU2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "dqnn = DeepQNN(spaceinvaders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GoUI0Ek7RNo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}