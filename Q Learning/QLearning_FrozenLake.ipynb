{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QLearning_FrozenLake.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HDaB-n8Cy4tG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3q9pJlbzc2J",
        "colab_type": "code",
        "outputId": "15e3a0f8-2adf-423d-ff89-4bdda42f6b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "env.render()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IjBFfJ7KziZg",
        "colab_type": "code",
        "outputId": "c17f4ee5-905d-4a2e-b06d-fbae35c9aea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "n_actions = env.action_space.n\n",
        "n_states = env.observation_space.n\n",
        "print('Number of actions: {}'.format(n_actions))\n",
        "print('Number of states: {}'.format(n_states))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of actions: 4\n",
            "Number of states: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylNOhwa2zr8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qtable = np.zeros((n_states,n_actions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVojtR6mzz9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_episodes = 15000        # Total episodes\n",
        "total_test_episodes = 100     # Total test episodes\n",
        "max_steps = 99                # Max steps per episode\n",
        "\n",
        "learning_rate = 0.5           # Learning rate\n",
        "gamma = 0.95                 # Discounting rate\n",
        "\n",
        "# Exploration parameters\n",
        "epsilon = 1.0                 # Exploration rate\n",
        "max_epsilon = 1.0             # Exploration probability at start\n",
        "min_epsilon = 0.01            # Minimum exploration probability \n",
        "decay_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AawKSt0s0ONl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "e13e1dd9-6c73-4579-ab3c-070540edc936"
      },
      "cell_type": "code",
      "source": [
        "rewards = []\n",
        "for episode in range(total_episodes):\n",
        "  state = env.reset()\n",
        "  total_rewards = 0\n",
        "  for step in range(max_steps):\n",
        "    exp_exp = random.uniform(0,1)\n",
        "    if exp_exp < epsilon:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      action = np.argmax(qtable[state,:])\n",
        "    new_s, reward, done, info = env.step(action)\n",
        "    qtable[state,action] += learning_rate*(reward+gamma*np.max(qtable[new_s,:])-qtable[state,action])\n",
        "    state = new_s\n",
        "    total_rewards += reward\n",
        "    if done:\n",
        "      break\n",
        "  \n",
        "  episode +=1\n",
        "  epsilon = min_epsilon + (max_epsilon-min_epsilon) * np.exp(-decay_rate*episode)\n",
        "  rewards.append(total_rewards)\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
        "print(qtable)    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.5382666666666667\n",
            "[[2.76039617e-01 1.08744907e-01 1.55731192e-01 1.30492202e-01]\n",
            " [3.60849072e-02 4.02008710e-02 2.24515517e-02 1.41361311e-01]\n",
            " [7.24798235e-02 2.09678227e-02 2.89015407e-02 2.98270997e-02]\n",
            " [2.19029930e-02 1.58797598e-02 7.82810150e-03 2.88085650e-02]\n",
            " [3.24915175e-01 3.51917527e-02 8.38078947e-02 3.18182861e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.84499370e-03 2.22129474e-04 3.65366204e-02 2.65510028e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.82641605e-01 2.83430007e-01 5.11868391e-02 4.43790860e-01]\n",
            " [1.15647973e-01 4.10878360e-01 7.77917122e-02 3.40503370e-01]\n",
            " [5.30442554e-01 4.77333907e-02 4.65501190e-02 4.95792297e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.31565090e-01 9.93516213e-02 5.59384638e-01 1.77743507e-01]\n",
            " [3.53832669e-01 8.54366399e-01 3.67520696e-01 4.85290903e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vyePEGyu2AgJ",
        "colab_type": "code",
        "outputId": "e3a2d9c8-25e2-49f5-a267-84bced22163d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1486
        }
      },
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(10):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    print(\"****************************************************\")\n",
        "    print(\"EPISODE \", episode)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        \n",
        "        # Take the action (index) that have the maximum expected future reward given that state\n",
        "        action = np.argmax(qtable[state,:])\n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            # Here, we decide to only print the last state (to see if our agent is on the goal or fall into an hole)\n",
        "            env.render()\n",
        "            \n",
        "            # We print the number of step it took.\n",
        "            print(\"Number of steps\", step)\n",
        "            break\n",
        "        state = new_state\n",
        "env.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************\n",
            "EPISODE  0\n",
            "  (Right)\n",
            "SFFF\n",
            "FHF\u001b[41mH\u001b[0m\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 50\n",
            "****************************************************\n",
            "EPISODE  1\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 5\n",
            "****************************************************\n",
            "EPISODE  2\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 8\n",
            "****************************************************\n",
            "EPISODE  3\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 32\n",
            "****************************************************\n",
            "EPISODE  4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 20\n",
            "****************************************************\n",
            "EPISODE  5\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 33\n",
            "****************************************************\n",
            "EPISODE  6\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 37\n",
            "****************************************************\n",
            "EPISODE  7\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 14\n",
            "****************************************************\n",
            "EPISODE  8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps 85\n",
            "****************************************************\n",
            "EPISODE  9\n",
            "  (Right)\n",
            "SFFF\n",
            "FHF\u001b[41mH\u001b[0m\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKYXngts2GtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}